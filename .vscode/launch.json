{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        
        {
            "name": "Interactive dialogger",
            "type": "python",
            "request": "launch",
            "program": "examples/interactive.py",
            "args": [
                "-m",
                "hugging_face/dialogger",
                "--gpt2-size",
                "medium",
            ],
            "console": "integratedTerminal"
        },
        {
            "name": "Interactive",
            "type": "python",
            "request": "launch",
            "program": "examples/interactive.py",
            "args": [
                "-m",
                "hugging_face/dialogpt",
                "--add-special-tokens",
                "False",
                "--gpt2-size",
                "medium",
                "--inference",
                "beam",
                "--beam-size",
                "10",
                "--beam-context-block-ngram",
                "3",
                "--beam-block-ngram",
                "3",
                "--beam-min-length",
                "25"
            ],
            "console": "integratedTerminal"
        },
        {
            "name": "Eval GPT2",
            "type": "python",
            "request": "launch",
            "program": "examples/eval_model.py",
            "args": [
                "-m",
                "hugging_face/gpt2",
                "-mf",
                "models/empathetic_dialogues/gpt2/gpt2",
                "--gpt2-size",
                "medium",
                "-t",
                "empathetic_dialogues",
                "--save-world-logs",
                "True",
                "--report-filename",
                "eval_results",
                "--add-special-tokens",
                "True",
                "-d",
                "True",
                "--inference",
                "topk"
            ],
            "console": "integratedTerminal"
        },
        {
            "name": "Eval GPT2-ed-neil",
            "type": "python",
            "request": "launch",
            "program": "examples/eval_model.py",
            "args": [
                "-m",
                "hugging_face/gpt2",
                "-mf",
                "models/gpt2-ed-neil/gpt2-ed-neil",
                "--gpt2-size",
                "medium",
                "-t",
                "neil",
                "--save-world-logs",
                "True",
                "--report-filename",
                "eval_results",
                "--add-special-tokens",
                "True",
                "-d",
                "True",
                "--inference",
                "topk",
                "--beam-size",
                "4",
                "-pt",
                "True"
            ],
            "console": "integratedTerminal"
        },
        {
            "name": "Eval DialoGPT",
            "type": "python",
            "request": "launch",
            "justMyCode": false,
            "program": "examples/eval_model.py",
            "args": [
                "-m",
                "hugging_face/dialogpt",
                "-mf",
                "models/empathetic_dialogues_mod/dialogpt_mc_ec-ed/dialogpt_mc_ec-ed",
                "--gpt2-size",
                "medium",
                "-t",
                "empathetic_dialogues_mod",
                "--save-world-logs",
                "True",
                "--report-filename",
                "eval_results",
                "--add-special-tokens",
                "True",
                "--inference",
                "topk",
                "--classes-from-file",
                "parlai/tasks/empathetic_dialogues_mod/classes.txt",
                "-d",
                "True"
            ],
            "console": "integratedTerminal"
        },
        {
            "name": "Train (dialogpt ED)",
            "type": "python",
            "request": "launch",
            "justMyCode": false,
            "program": "examples/train_model.py",
            "args": [
                "-m",
                "hugging_face/dialogpt",
                "--add-special-tokens",
                "True",
                "--add-start-token",
                "False",
                "--gpt2-size",
                "medium",
                "-t",
                "empathetic_dialogues",
                "-tblog",
                "True",
                "-bs",
                "1",
                "-vtim",
                "3600",
                "-mf",
                "models/debug/dialogpt-mc-ec/dialogpt-mc-ec",
                "--inference",
                "beam",
                "--beam-size",
                "10",
                "--beam-context-block-ngram",
                "3",
                "--beam-block-ngram",
                "3",
                "--beam-min-length",
                "25",
                "--update-freq",
                "2",
                "--optimizer",
                "adam",
                "-lr",
                "6.25e-5",
                "-pt",
                "True"
            ],
            "console": "integratedTerminal"
        },
        {
            "name": "Train (dialogpt-mc-ec ED)",
            "type": "python",
            "request": "launch",
            "justMyCode": false,
            "program": "examples/train_model.py",
            "args": [
                "-m",
                "hugging_face/dialogpt",
                "--add-special-tokens",
                "True",
                "--next_sentence_prediction",
                "True",
                "--emotion-prediction",
                "True",
                "--classes-from-file",
                "parlai/tasks/empathetic_dialogues_mod/classes.txt",
                "--add-start-token",
                "False",
                "--gpt2-size",
                "medium",
                "-t",
                "empathetic_dialogues_mod",
                "-tblog",
                "True",
                "-bs",
                "1",
                "-vtim",
                "10",
                "-mf",
                "models/debug/dialogpt-mc-ec/dialogpt-mc-ec",
                "--inference",
                "beam",
                "--beam-size",
                "10",
                "--beam-context-block-ngram",
                "3",
                "--beam-block-ngram",
                "3",
                "--beam-min-length",
                "25",
                "--update-freq",
                "2",
                "--optimizer",
                "adam",
                "-lr",
                "6.25e-5",
                "-pt",
                "True",
                "--no-cuda"
            ],
            "console": "integratedTerminal"
        },
        {
            "name": "Train (dialogpt-mc-ec neil)",
            "type": "python",
            "request": "launch",
            "justMyCode": false,
            "program": "examples/train_model.py",
            "args": [
                "-m",
                "hugging_face/dialogpt",
                "--add-special-tokens",
                "True",
                "--next_sentence_prediction",
                "True",
                "--emotion-estimation",
                "True",
                "--add-start-token",
                "False",
                "--label-truncate",
                "100"
                "--gpt2-size",
                "medium",
                "-t",
                "neil",
                "-tblog",
                "True",
                "-bs",
                "1",
                "-vtim",
                "10",
                "-mf",
                "models/debug/dialogpt_mc_ec-neil/dialogpt_mc_ec-neil",
                "-im",
                "models/empathetic_dialogues_mod/dialogpt_mc_ec-ed/dialogpt_mc_ec-ed",
                "--inference",
                "beam",
                "--beam-size",
                "10",
                "--beam-context-block-ngram",
                "3",
                "--beam-block-ngram",
                "3",
                "--beam-min-length",
                "25",
                "--update-freq",
                "2",
                "--optimizer",
                "adam",
                "-lr",
                "6.25e-5",
                "-pt",
                "True",
                "-vmt",
                "token_acc",
                "--skip-generation",
                "True"
            ],
            "console": "integratedTerminal"
        },
        {
            "name": "Train (gpt2 ED)",
            "type": "python",
            "request": "launch",
            "program": "examples/train_model.py",
            "args": [
                "-m",
                "hugging_face/gpt2",
                "--add-special-tokens",
                "True",
                "--add-start-token",
                "False",
                "--gpt2-size",
                "medium",
                "-t",
                "empathetic_dialogues",
                "-tblog",
                "True",
                "-bs",
                "1",
                "-vtim",
                "3600",
                "-mf",
                "models/debug/gpt2",
                "--inference",
                "topk",
                "--topk",
                "10",
                "--beam-size",
                "10",
                "--beam-context-block-ngram",
                "3",
                "--beam-block-ngram",
                "3",
                "--beam-min-length",
                "25"
            ],
            "console": "integratedTerminal"
        },        
        {
            "name": "Train (dialogpt neil)",
            "type": "python",
            "request": "launch",
            "program": "examples/train_model.py",
            "args": [
                "-m",
                "hugging_face/dialogpt",
                "--add-special-tokens",
                "True",
                "--add-start-token",
                "False",
                "--gpt2-size",
                "medium",
                "-t",
                "neil",
                "-tblog",
                "True",
                "-bs",
                "1",
                "-vtim",
                "10",
                "-mf",
                "models/neil/dialogpt/dialogpt",
                "--inference",
                "beam",
                "--beam-size",
                "10",
                "--beam-context-block-ngram",
                "3",
                "--beam-block-ngram",
                "3",
                "--beam-min-length",
                "25"
            ],
            "console": "integratedTerminal"
        },
        {
            "name": "Display (FT)",
            "type": "python",
            "request": "launch",
            "program": "examples/display_model.py",
            "args": [
                "-m",
                "hugging_face/dialogpt",
                "--add-special-tokens",
                "False",
                "--add-start-token",
                "False",
                "--gpt2-size",
                "medium",
                "-t",
                "dailydialog",
                "-mf",
                "models/dialogpt-ED/dialogpt-ED",
                "--inference",
                "beam",
                "--beam-size",
                "10",
                "--beam-context-block-ngram",
                "3",
                "--beam-block-ngram",
                "3",
                "--beam-min-length",
                "25"
            ],
            "console": "integratedTerminal"
        },
        {
            "name": "Display (base)",
            "type": "python",
            "request": "launch",
            "program": "examples/display_model.py",
            "args": [
                "-m",
                "hugging_face/dialogpt",
                "--add-special-tokens",
                "False",
                "--add-start-token",
                "False",
                "--gpt2-size",
                "medium",
                "-t",
                "empathetic_dialogues",
                "--inference",
                "beam",
                "--beam-size",
                "10",
                "--beam-context-block-ngram",
                "3",
                "--beam-block-ngram",
                "3",
                "--beam-min-length",
                "25"
            ],
            "console": "integratedTerminal"
        },
        {
            "name": "Display (base)",
            "type": "python",
            "request": "launch",
            "program": "examples/display_model.py",
            "args": [
                "-t",
                "twitter",
                "-mf",
                "/tmp/tr_twitter",
                "-m",
                "transformer/ranker",
                "-bs",
                "10",
                "-vtim",
                "3600",
                "-cands",
                "batch",
                "-ecands",
                "batch",
                "--data-parallel",
                "True"
            ],
            "console": "integratedTerminal"
        }
    ]
}